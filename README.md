# INverse Forward Offline Reinforcement Model (INFORM)

#### Codebase for : "Learning while sleeping: Integrating Sleep-Inspired Consolidation with Human Feedback Learning"

<!DOCTYPE html>
<html>
<head>
    <title>INFORM Framework</title>
</head>
<body>

<h1>INverse Forward Offline Reinforcement Model (INFORM)</h1>

<p>The INverse Forward Offline Reinforcement Model (INFORM) is a framework that scalably learns generalised policies and reward functions from human feedback. The model consists of two phases:</p>

<h2>1. A Forward model</h2>
<p>In this initial phase, we use a myopic interactive RL based on human feedback to train a preliminary, low-level policy.</p>

<h2>2. An Offline Inverse model</h2>
<p>Subsequently, we revisit all the trajectories generated by the previous phase and apply a non-myopic offline IRL to derive a policy and reward function that more accurately capture the task's high-level objectives.</p>

</body>
</html>
